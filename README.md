# VectorMind

**VectorMind** is a **localâ€‘first** AIâ€‘powered documentâ€‘understanding toolkit that blends fast vector search with LLMâ€‘ready retrieval.

---

## ğŸ”§ Stack

* ğŸ§  **Embedding**â€‚Â·â€‚`MiniLMâ€‘L6â€‘v2` (local Sentenceâ€‘Transformers)
* ğŸ“¦ **Vector DB**â€‚Â·â€‚Weaviate (Docker selfâ€‘hosted)
* â˜• **Backend**â€‚Â·â€‚Spring Boot (Java)
* ğŸ **Embedder**â€‚Â·â€‚Flask (Python)
* ğŸ” **RAG Logic**â€‚Â·â€‚Similarity searchÂ â†’ context â†’ LLM (plugâ€‘in)

---

## âœ… Current Features

* ğŸ“¤ Upload **PDF** or **TXT**
* ğŸ“‘ Autoâ€‘chunk & embed text
* ğŸ—„ Store vectors in Weaviate
* ğŸ” Ask questions â†’ returns topâ€‘matching chunks (RAGâ€‘ready JSON)

---

## ğŸš§ Roadmap / Coming Soon

| Feature                        | Status        |
| ------------------------------ | ------------- |
| ğŸ’¬ LLM answers (Groq / Gemini) | â³ In progress |
| ğŸŒ React frontend (dark UI)    | â³ Planned     |
| ğŸ”„ Multiâ€‘LLM switcher          | â³ Planned     |
| â˜ï¸ AWS / Fargate deployment    | â³ Planned     |

---

## âš™ï¸ Run Locally

```bash
# 1. Clone
 git clone https://github.com/TejasGuptaX7/VectorMind.git && cd VectorMind

# 2. Start Weaviate
 docker compose up -d  # exposes :8080

# 3. Start Spring Boot (port 8082)
 cd api
 ./mvnw spring-boot:run

# 4. Start Embedder (port 5001)
 cd ../embedder
 python3 -m venv venv && source venv/bin/activate
 pip install -r requirements.txt
 python embedder.py
```

> Frontâ€‘end & RAG answer endpoint will run on `localhost:8082` once upcoming features land.

---

## ğŸ“ License

MIT â€” fork, extend, and build your own killer feature.
